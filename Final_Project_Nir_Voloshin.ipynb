{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'mldata.org dataset: mnist-original', 'COL_NAMES': ['label', 'data'], 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.]), 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "# Loading the MNIST data\n",
    "mnist = fetch_mldata('MNIST original', data_home = os.getcwd())\n",
    "print(mnist)\n",
    "\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "X_data = images\n",
    "Y = targets\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the y_train vector to the X_train matrix so that I can split the observations into clusters based\n",
    "# on their labels\n",
    "X_train_new = np.concatenate((y_train[:, np.newaxis], X_train), axis=1)\n",
    "cluster_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculating the mean of each cluster\n",
    "for i in range(10):\n",
    "    sub_mat = X_train_new[np.where(X_train_new[:,0] == i)].mean(axis=0)\n",
    "    cluster_means.append(sub_mat)\n",
    "    cluster_means[i] = cluster_means[i].reshape(X_train_new.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def euclidean_distance(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "def assign_cluster(a,centers):\n",
    "    dists = np.array([euclidean_distance(a,x[1:]) for x in centers])\n",
    "    return np.argmin(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###### APPROACH 1 #########\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    c = assign_cluster(X_test[i,:],cluster_means)\n",
    "    if c == y_test[i]:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1700952380952381"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The acccuracy rate by using the first method\n",
    "acc_rate = correct/len(X_test)\n",
    "acc_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data required for testing to determine which k is the best\n",
    "(train_data,val_data,train_labels,val_labels) = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=97.50%\n",
      "k=3, accuracy=97.16%\n",
      "k=5, accuracy=97.11%\n",
      "k=7, accuracy=96.91%\n",
      "k=9, accuracy=96.64%\n"
     ]
    }
   ],
   "source": [
    "###### APPROACH 2 #########\n",
    "percentages = []\n",
    "\n",
    "# Testing which k gives the highest accuracy by testing the model on the validation data\n",
    "for k in range(1,10,2):\n",
    "    model = KNeighborsClassifier(n_neighbors = k)\n",
    "    model.fit(train_data,train_labels)\n",
    "    \n",
    "    # evaluate the model and update the accuracies list\n",
    "    score = model.score(val_data,val_labels)\n",
    "    print('k=%d, accuracy=%.2f%%' % (k,score*100))\n",
    "    percentages.append(score)\n",
    "\n",
    "accuracies = np.array(percentages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 achieved the highest accuracy of 97.50% on the validation data\n"
     ]
    }
   ],
   "source": [
    "# finding the value of k that has the highest accuracy\n",
    "i = np.argmax(accuracies)\n",
    "kVals = [i for i in range(1,10,2)]\n",
    "print('k = %d achieved the highest accuracy of %.2f%% on the validation data' % (kVals[i], accuracies[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best k on the original training and test data to calculate the accuracy\n",
    "model = KNeighborsClassifier(n_neighbors = 1)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on testing data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      1024\n",
      "        1.0       0.97      1.00      0.99      1185\n",
      "        2.0       0.99      0.96      0.98      1051\n",
      "        3.0       0.97      0.97      0.97      1057\n",
      "        4.0       0.98      0.97      0.97       964\n",
      "        5.0       0.97      0.97      0.97       964\n",
      "        6.0       0.98      0.99      0.99      1085\n",
      "        7.0       0.96      0.98      0.97      1128\n",
      "        8.0       0.98      0.95      0.96      1037\n",
      "        9.0       0.95      0.95      0.95      1005\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show a final classification report that demonstrates the accuracy of the classifier \n",
    "# for each of the digits\n",
    "print(\"Evaluation on testing data:\")\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
