{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original', data_home=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'COL_NAMES': ['label', 'data'],\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-06-11 16:55:24.055005\n",
      "Stop learning 2018-06-11 17:37:53.928290\n",
      "Elapsed learning 0:42:29.873285\n",
      "Classification report for classifier SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1024\n",
      "        1.0       0.99      0.99      0.99      1185\n",
      "        2.0       0.98      0.99      0.98      1051\n",
      "        3.0       0.98      0.98      0.98      1057\n",
      "        4.0       0.99      0.99      0.99       964\n",
      "        5.0       0.98      0.98      0.98       964\n",
      "        6.0       0.99      0.99      0.99      1085\n",
      "        7.0       0.99      0.98      0.99      1128\n",
      "        8.0       0.97      0.98      0.97      1037\n",
      "        9.0       0.98      0.97      0.98      1005\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10500\n",
      "\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[1014    0    2    0    0    2    2    0    1    3]\n",
      " [   0 1177    2    1    1    0    1    0    2    1]\n",
      " [   2    2 1037    2    0    0    0    2    5    1]\n",
      " [   0    0    3 1035    0    5    0    6    6    2]\n",
      " [   0    0    1    0  957    0    1    2    0    3]\n",
      " [   1    1    0    4    1  947    4    0    5    1]\n",
      " [   2    0    1    0    2    0 1076    0    4    0]\n",
      " [   1    1    8    1    1    0    0 1110    2    4]\n",
      " [   0    4    2    4    1    6    0    1 1018    1]\n",
      " [   3    1    0    7    5    2    0    4    9  974]]\n"
     ]
    }
   ],
   "source": [
    "# data is 70,000 x 784 array where each row represents pixels from a (28 x 28) = 784 image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# Let's have a look at the random 16 images, \n",
    "# We have to reshape each data row, from flat array of 784 int to 28x28 2D array\n",
    "\n",
    "# pick  random indexes from 0 to size of our dataset\n",
    "# show_some_digits(images,targets)\n",
    "\n",
    "# #---------------- classification begins -----------------\n",
    "# scale data for [0,255] -> [0,1]\n",
    "# sample smaller size for testing\n",
    "rand_idx = np.random.choice(images.shape[0],10000)\n",
    "X_data =images[rand_idx]/255.0\n",
    "Y = targets[rand_idx]\n",
    "\n",
    "#full dataset classification\n",
    "# X_data = images/255.0\n",
    "# Y = targets\n",
    "\n",
    "# #split data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "classifier = svm.SVC(C=param_C, gamma=param_gamma)\n",
    "\n",
    "# We learn the digits on train part\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time = end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "\n",
    "\n",
    "# predict the value of the test\n",
    "expected = y_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "# show_some_digits(X_test,predicted,title_text=\"Predicted {}\")\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (classifier, metrics.classification_report(expected, predicted)))\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "# print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=Y, title='Confusion matrix, without normalization')\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e0ce1bc3506f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cnn'"
     ]
    }
   ],
   "source": [
    "# CNN Method\n",
    "from sklearn import model_selection\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "from cnn import CNN\n",
    "import argparse\n",
    "from keras import optimizers\n",
    "\n",
    "mnist_data = images.reshape((images.shape[0], 28, 28))\n",
    "mnist_data = mnist_data[:, np.newaxis, :, :]\n",
    "train_img, test_img, train_labels, test_labels = model_selection.train_test_split(mnist_data/255.0, targets.astype(\"int\"), test_size=0.1)\n",
    "img_rows,img_columns = 28,28\n",
    "total_classes = 10\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "\n",
    "sgd = optimisers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "clf = CNN(width=img_rows, height=img_columns, depth=1, total_classes=total_classes, weightsPath=args[\"weights\"])\n",
    "clf.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "b_size = 128 # Batch size\n",
    "num_epoch = 20 # Number of epochs\n",
    "verb = 1 # Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
